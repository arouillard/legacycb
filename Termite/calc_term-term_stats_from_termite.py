# -*- coding: utf-8 -*-
"""
Andrew D. Rouillard
Computational Biologist
Target Sciences
GSK
andrew.d.rouillard@gsk.com
"""

import argparse
import gzip
import numpy as np
import datasetIO
from scipy.stats import hypergeom

def pointentropy(subset_count, total_count):
    if subset_count == 0:
        return 0
    else:
        return (subset_count/total_count)*(np.log2(total_count) - np.log2(subset_count))

def mutualinformation(tp, fp, fn, tn):
    n = tp + fp + fn + tn
    Hr = pointentropy(tp+fp,n) + pointentropy(fn+tn,n)
    Hc = pointentropy(tp+fn,n) + pointentropy(fp+tn,n)
    Hrc = pointentropy(tp,n) + pointentropy(fp,n) + pointentropy(fn,n) + pointentropy(tn,n)
    mi = Hr + Hc - Hrc
    nmi = mi/np.sqrt(Hr*Hc)
    iqr = mi/Hrc
    return mi, nmi, iqr

def main(dictionaries, year, datestamp, min_score, universe, n_prior, min_count):
    
    print('begin calc_term-term_stats_from_termite.py')
    
    print('dictionaries: {0}, {1}'.format(dictionaries[0], dictionaries[1]))
    print('year: {0}'.format(year))
    print('datestamp: {0}'.format(datestamp))
    print('min_score: {0!s}'.format(min_score))
    print('universe: {0}'.format(universe))
    print('n_prior: {0!s}'.format(n_prior))
    print('min_count: {0!s}'.format(min_count))
    
    # load counts datamatrix
    # this file is generated by count_term-term_pmids_from_termite.py    
    print('loading counts datamatrix...')
    row_dictionary = dictionaries[0] # 'HUCELL', 'ANAT', 'INDICATION', 'HUCELLANAT', 'HUCELLANATINDICATION'
    column_dictionary = dictionaries[1] # 'HUCELL', 'ANAT', 'INDICATION', 'HUCELLANAT', 'HUCELLANATINDICATION'
    counts_datamatrix_path = '{0}_{1}_datamatrix_pmidcounts_year_{2}_datestamp_{3}_minscore_{4!s}.pickle'.format(row_dictionary, column_dictionary, year, datestamp, min_score)
    term_term = datasetIO.load_datamatrix(counts_datamatrix_path)
    print('counts_datamatrix_path: {0}'.format(counts_datamatrix_path))
    print(term_term)
    
    # find term-term pairs with sufficient counts
    print('finding term-term pairs with sufficient counts...')
    I, J = (term_term.matrix >= min_count).nonzero()
    num_sufficient = I.size
    print('term-term pairs with at least {0!s} counts: {1!s}'.format(min_count, num_sufficient))
    
    # convert counts to float
    print('converting counts to float...')
    term_term.matrix = np.float64(term_term.matrix)
    term_term.updatedtypeattribute()
    for field, values in term_term.rowmeta.items():
        if values.dtype == np.int64:
            term_term.rowmeta[field] = np.float64(values)
    for field, values in term_term.columnmeta.items():
        if values.dtype == np.int64:
            term_term.columnmeta[field] = np.float64(values)
    
    # set universe size
    print('setting universe size...')
    if universe == 'intersectionunion' or universe == 'union':
        universe_size = term_term.rowmeta['all_count_{0}'.format(universe)][0]
    elif universe == 'medline':
        universe_size = 1e8 # 3e7
        term_term.rowmeta['term_count_medline'] = term_term.rowmeta['term_count_union'].copy()
        term_term.columnmeta['term_count_medline'] = term_term.columnmeta['term_count_union'].copy()
    elif universe == 'infinity':
        universe_size = 1e16
        term_term.rowmeta['term_count_infinity'] = term_term.rowmeta['term_count_union'].copy()
        term_term.columnmeta['term_count_infinity'] = term_term.columnmeta['term_count_union'].copy()
    else:
        raise ValueError('invalid universe')
    
    # create matrices for select association statistics
    print('creating matrices for select association statistics...')
    selstats = ['mcc', 'mmcc', 'cos', 'mi', 'nmi', 'iqr']
    statmats = {}
    for selstat in selstats:
        statmats[selstat] = np.zeros(term_term.shape, dtype='float64')
    
    # calculate association statistics and write to dataframe
    print('calculating association statistics and writing to dataframe...')
    dataframe_path = '{0}_{1}_dataframe_yr_{2}_ds_{3}_ms_{4!s}_uv_{5}_np_{6!s}_mc_{7!s}.txt.gz'.format(row_dictionary, column_dictionary, year, datestamp, min_score, universe, n_prior, min_count)
    rowmetalabels = ['term_id', 'term_name']
    rowmetaheaders = ['{0}_id'.format(row_dictionary), '{0}_name'.format(row_dictionary)]
    columnmetalabels = ['term_id', 'term_name']
    columnmetaheaders = ['{0}_id'.format(column_dictionary), '{0}_name'.format(column_dictionary)]
    statheaders = ['tp', 'fn', 'tn', 'fp', 'ap', 'an', 'pp', 'pn', 'n', 'tpr', 'fnr', 'tnr', 'fpr', 'ppv', 'fdr', 'npv', 'fomr', 'acc', 'mcr', 'prev', 'plr', 'nlr', 'dor', 'drr', 'darr', 'mrr', 'marr', 'f1', 'mcc', 'mmcc', 'cos', 'fnlp', 'sig', 'lrr', 'lrr_se', 'lrr_lb95', 'lrr_ub95', 'drr_lb95', 'drr_ub95', 'lor', 'lor_se', 'lor_lb95', 'lor_ub95', 'dor_lb95', 'dor_ub95', 'mi', 'nmi', 'iqr']
    with gzip.open(dataframe_path, mode='wt', encoding='utf-8', errors='surrogateescape') as fw:
        writelist = ['{0}_dictidname'.format(row_dictionary)] + rowmetaheaders + ['{0}_dictidname'.format(column_dictionary)] + columnmetaheaders + statheaders
        fw.write('\t'.join(writelist) + '\n')
        for k, (i, j) in enumerate(zip(I, J)):
            if np.mod(k, 1000) == 0 or k+1 == num_sufficient:
                print('working on term-term pair {0!s} of {1!s}...'.format(k+1, num_sufficient))
            
            # confusion matrix
            tp = term_term.matrix[i,j]
            fp = term_term.rowmeta['term_count_{0}'.format(universe)][i] - tp
            fn = term_term.columnmeta['term_count_{0}'.format(universe)][j] - tp
            tn = universe_size - (tp + fp + fn)
            
            # incorporate a random prior with effective sample size = n_prior,
            # where prior distribution conforms to empirical marginal distributions
            Rr = (tp+fp)/(fn+tn) # ratio of rows of confusion matrix
            Rc = (tp+fn)/(fp+tn) # ratio of columns of confusion matrix
            tp_prior = n_prior*Rc*Rr/(Rc*Rr + Rr + Rc + 1) # solve for tp given constraints tp/fn=Rr, fp/tn=Rr, tp/fp=Rc, fn/tn=Rc, tp+fp+fn+tn=n_eff
            fp_prior = tp_prior/Rc
            fn_prior = tp_prior/Rr
            tn_prior = tp_prior/Rc/Rr
            tp += tp_prior
            fp += fp_prior
            fn += fn_prior
            tn += tn_prior
            
            ap = tp + fn
            an = fp + tn
            pp = tp + fp
            pn = tn + fn
            n = tn + fp + fn + tp
            
            tpr = tp/ap # sensitivity, recall
            fnr = fn/ap # 1-tpr, 1-sensitivity, 1-recall
            tnr = tn/an # specificity
            fpr = fp/an # 1-tnr, 1-specificity
            
            ppv = tp/pp # precision
            fdr = fp/pp # 1-ppv, 1-precision
            npv = tn/pn
            fomr = fn/pn # 1-npv
            
            acc = (tp + tn)/n
            mcr = (fp + fn)/n # 1-acc
            prev = ap/n
            
            plr = (tp/fp)/(ap/an) # tpr/fpr, sensitivity/(1-specificity), ratio of positives to negatives in positive predictions relative to ratio in whole sample, higher is better
            nlr = (fn/tn)/(ap/an) # fnr/tnr, (1-sensitivity)/specificity, ratio of positives to negatives in negative predictions relative to ratio in whole sample, lower is better
            dor = (tp/fp)/(fn/tn) # plr/nlr, ratio of positives to negatives in positive predictions, divided by ratio of positives to negatives in negative predictions
            drr = (tp/pp)/(fn/pn) # ppv/fomr, relative risk or risk ratio, fraction of positives in positive predictions divided by fraction of positives in negative predictions
            darr = (tp/pp) - (fn/pn) # ppv - fomr, absolute risk reduction, fraction of positives in positive predictions minus fraction of positives in negative predictions
            mrr = (tp/pp)/(ap/n) # ppv/prev, modified (by me) relative risk or risk ratio, fraction of positives in positive predictions divided by fraction of positives in whole sample
            marr = (tp/pp) - (ap/n) # ppv - prev, modified (by me) absolute risk reduction, fraction of positives in positive predictions minus fraction of positives in whole sample
            
            f1 = (1 + (1**2))*ppv*tpr/((1**2)*ppv + tpr)
            mcc = (tp*tn - fp*fn)/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))
            mmcc = 1 - np.sqrt((fp*fn)/((tp+fp)*(tp+fn))) # modified (by me), equivalent to 1 + mcc with tn forced to 0
            cos = tp/np.sqrt((tp+fp)*(tp+fn)) # ochiai
            fnlp = -hypergeom.logsf(tp, n, ap, pp, loc=1)/np.log(10)
            sig = fnlp > np.log10(term_term.size) - np.log10(0.05)
            
            lrr = np.log10(tp) - np.log10(tp+fp) - np.log10(fn) + np.log10(fn+tn) # log10 of relative risk
            lrr_se = np.sqrt(fp/tp/(tp+fp) + tn/fn/(fn+tn))/np.log(10) # standard error of log10 of relative risk
            lrr_lb95 = lrr - 1.96*lrr_se
            lrr_ub95 = lrr + 1.96*lrr_se
            drr_lb95 = 10**lrr_lb95
            drr_ub95 = 10**lrr_ub95
            
            lor = np.log10(tp) - np.log10(fp) - np.log10(fn) + np.log10(tn) # log10 of odds ratio
            lor_se = np.sqrt(1/tp + 1/fp + 1/fn + 1/tn)/np.log(10) # standard error of log10 of odds ratio
            lor_lb95 = lor - 1.96*lor_se
            lor_ub95 = lor + 1.96*lor_se
            dor_lb95 = 10**lor_lb95
            dor_ub95 = 10**lor_ub95
            
            mi, nmi, iqr = mutualinformation(tp, fp, fn, tn) # mutual information, normalized mutual information, information quality ratio
            
            count_stats = [tp, fn, tn, fp, ap, an, pp, pn, n]
            other_stats = [tpr, fnr, tnr, fpr, ppv, fdr, npv, fomr, acc, mcr, prev, plr, nlr, dor, drr, darr, mrr, marr, f1, mcc, mmcc, cos, fnlp, sig, lrr, lrr_se, lrr_lb95, lrr_ub95, drr_lb95, drr_ub95, lor, lor_se, lor_lb95, lor_ub95, dor_lb95, dor_ub95, mi, nmi, iqr]
            
            rowwritelist = [term_term.rowlabels[i]] + [term_term.rowmeta[l][i] if term_term.rowmeta[l].dtype=='object' else str(term_term.rowmeta[l][i]) for l in rowmetalabels]
            columnwritelist = [term_term.columnlabels[j]] + [term_term.columnmeta[l][j] if term_term.columnmeta[l].dtype=='object' else str(term_term.columnmeta[l][j]) for l in columnmetalabels]
            writelist = rowwritelist + columnwritelist + [str(s) for s in count_stats] + ['{0:1.5g}'.format(s) for s in other_stats]
            fw.write('\t'.join(writelist) + '\n')
        
            statmats['mcc'][i,j] = mcc
            statmats['mmcc'][i,j] = mmcc
            statmats['cos'][i,j] = cos
            statmats['mi'][i,j] = mi
            statmats['nmi'][i,j] = nmi
            statmats['iqr'][i,j] = iqr

    # save matrices for select association statistics
    print('saving matrices for select association statistics...')
    for selstat in selstats:
        term_term.matrix = statmats[selstat]
        datasetIO.save_datamatrix('{0}_{1}_datamatrix_{2}_yr_{3}_ds_{4}_ms_{5!s}_uv_{6}_np_{7!s}_mc_{8!s}.txt.gz'.format(row_dictionary, column_dictionary, selstat, year, datestamp, min_score, universe, n_prior, min_count), term_term)
        datasetIO.save_datamatrix('{0}_{1}_datamatrix_{2}_yr_{3}_ds_{4}_ms_{5!s}_uv_{6}_np_{7!s}_mc_{8!s}.pickle'.format(row_dictionary, column_dictionary, selstat, year, datestamp, min_score, universe, n_prior, min_count), term_term)

    print('done calc_term-term_stats_from_termite.py')
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Get term-term association statistics from termite.')
    parser.add_argument('--dictionaries', help='two dictionaries of biomedical terms, first for row terms and second for column terms', type=str, nargs='+')
    parser.add_argument('--year', help='year of termite file', type=str, default='all')
    parser.add_argument('--datestamp', help='datestamp of termite file', type=str, default='all')
    parser.add_argument('--min_score', help='min score for filtering term-pmid associations', type=int, default=2)
    parser.add_argument('--universe', help='the full set of publications considered in the analysis (intersectionunion, union, medline, or infinity)', type=str, default='intersectionunion')
    parser.add_argument('--n_prior', help='prior effective sample size', type=int, default=1)
    parser.add_argument('--min_count', help='min term-term count for computing association statistics', type=int, default=5)
    args = parser.parse_args()
    main(args.dictionaries, args.year, args.datestamp, args.min_score, args.universe, args.n_prior, args.min_count)
